{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTFeatureExtractor, ViTImageProcessor\n",
    "\n",
    "from pathlib import Path as path\n",
    "from PIL import Image\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-384')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, folder_path, sample_tuple):\n",
    "        self.folder_path = folder_path\n",
    "        self.sample_tuple = sample_tuple\n",
    "        # self.feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-384')\n",
    "        self.feature_extractor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-384')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_tuple)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.sample_tuple[idx]\n",
    "\n",
    "        img = Image.open(path.joinpath(self.folder_path, img_path)).convert('RGB')\n",
    "        encoding = self.feature_extractor(images=img, return_tensors=\"pt\")\n",
    "\n",
    "        return encoding['pixel_values'][0], label\n",
    "        \n",
    "    @classmethod\n",
    "    def from_path(cls, folder_path, split):\n",
    "        c2i, i2c = {}, {}\n",
    "        \n",
    "        with open(path.joinpath(folder_path, 'LOC_synset_mapping.txt')) as f:\n",
    "            for i, line in enumerate(f.readlines()):\n",
    "                segments = line.strip().split(' ')\n",
    "                label_idx = segments[0]\n",
    "                c2i[label_idx] = i\n",
    "                i2c[i] = label_idx\n",
    "\n",
    "        def _read_path(row):\n",
    "            sample_id = row[0]\n",
    "            strings = sample_id.split('_')\n",
    "            split = strings[1] if strings[0] == 'ILSVRC2012' else 'train'\n",
    "        \n",
    "            file_path = path('ILSVRC', 'Data', 'CLS-LOC')\n",
    "            if split == 'train':\n",
    "                file_path = path.joinpath(file_path, strings[0], strings[1], f'{sample_id}.JPEG')\n",
    "            else:\n",
    "                file_path = path.joinpath(file_path, split, f'{sample_id}.JPEG')\n",
    "\n",
    "            # label_name, *bboxes = row[1].strip().split(' ')\n",
    "            label_name = row[1].strip().split(' ')[0]\n",
    "            label_id = c2i[label_name]\n",
    "\n",
    "            return (file_path, label_id)\n",
    "\n",
    "        with open(path.joinpath(folder_path, 'LOC_val_solution.csv')) as csv_file:\n",
    "            dt = csv.reader(csv_file)\n",
    "            next(dt)  # skip header row\n",
    "            sample_tuple = list(map(_read_path, dt))\n",
    "            # for a in dt:\n",
    "            #     print(a)\n",
    "            #     print(_read_path(a))\n",
    "            #     break\n",
    "        # print(sample_tuple[0])\n",
    "        return cls(folder_path, sample_tuple)\n",
    "        \n",
    "\n",
    "val_ds = ImageNetDataset.from_path(\n",
    "    folder_path=path.joinpath(path.home(), 'datasets', 'ImageNet'),\n",
    "    split='val'\n",
    ")\n",
    "# for i, sample in enumerate(val_ds):\n",
    "#     print(f'\\r{i} {sample[0].shape}', end='')\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3124\\31250.8391\n"
     ]
    }
   ],
   "source": [
    "count, total = 0, 0\n",
    "for i, (images, labels) in enumerate(val_loader):\n",
    "    print(f'\\r{i}\\{len(val_loader)}', end='')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images.to(device))\n",
    "    pred = outputs.logits.argmax(-1)\n",
    "    acc = labels.eq(pred.cpu())\n",
    "    count += acc.sum().item()\n",
    "    total += labels.shape[0]\n",
    "\n",
    "print(count / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8391\n"
     ]
    }
   ],
   "source": [
    "print(count / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02ddec9fcab8f92c86f4c81cce59b33abae57b94c6ac12443177fb94b53887b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
