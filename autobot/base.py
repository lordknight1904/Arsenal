import torch
from torch import nn


class MultiHeadAttention(nn.Module):

    class __init__(self):
        super().__init__()
        
    def forward(self, x):
        return x
