{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "from dataclasses import dataclass\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from typing import List, Tuple\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3D_location': array([-1.99999883,  0.20000001, -3.00000075]), 'bboxes': [{'center': array([1884.,  734.]), 'size': array([ 47., 176.])}, {'center': array([2299.,  827.]), 'size': array([106., 262.])}], 'cameras': [{'filename': 'step0.camera_0.png', 'position': [8.0, 2.5, 3.0], 'rotation': [16, 240, 0]}, {'filename': 'step0.camera.png', 'position': [-7.0, 2.5, 3.0], 'rotation': [17, 130, 0]}]}\n"
     ]
    }
   ],
   "source": [
    "with open('./solo/sequence.0/step0.frame_data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "captures = data['captures']\n",
    "def get_location(captures):\n",
    "    # coeff = np.array([-0.00389254, 0.49512566, 0.13212298])\n",
    "\n",
    "    def _find(l, s):\n",
    "        for elem in l:\n",
    "            if elem['id'] == s or elem['id'] == f'{s}_0':\n",
    "                return elem['values'][0]\n",
    "    \n",
    "    def _get_bbox(view):\n",
    "        '''\n",
    "            For each view, extract the 2D bounding box and\n",
    "        '''\n",
    "        bbox_3d, bbox_2d = _find(view['annotations'], 'bounding box 3D'), _find(view['annotations'], 'bounding box')\n",
    "        \n",
    "        # refine 3D location of the object\n",
    "        euler = R.from_quat(bbox_3d.get('rotation')).as_matrix()\n",
    "        obj_location = view.get('position') + np.dot(bbox_3d['translation'], euler) - bbox_3d['size']*np.array([-0.00389254, 0.49512566, 0.13212298])\n",
    "\n",
    "        # pre-process 2D bbox\n",
    "        bbox = {\n",
    "            'center': np.array(bbox_2d['origin']) + np.array(bbox_2d['dimension'])/2,\n",
    "            'size': np.array(bbox_2d['dimension'])/2,\n",
    "        }\n",
    "\n",
    "        return obj_location, bbox\n",
    "\n",
    "    angles = [\n",
    "        [16, 240, 0],\n",
    "        [17, 130, 0],\n",
    "        # [16, 0, 240],\n",
    "        # [17, 0, 130],\n",
    "    ]\n",
    "    bboxes, cameras = [], []\n",
    "    for i, view in enumerate(captures):  # per view\n",
    "        obj_location, bbox_2d = _get_bbox(view)\n",
    "\n",
    "        bboxes.append(bbox_2d)\n",
    "        cameras.append({\n",
    "            'filename': view['filename'],\n",
    "            'position': view['position'],\n",
    "            # 'rotation': view['rotation'],\n",
    "            'rotation': angles[i],\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        '3D_location': obj_location,\n",
    "        'bboxes': bboxes,\n",
    "        'cameras': cameras,\n",
    "    }\n",
    "\n",
    "output = get_location(captures)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1920. -1080.]\n",
      " [-1920.  1080.]\n",
      " [ 1920. -1080.]\n",
      " [ 1920.  1080.]\n",
      " [    0.     0.]]\n",
      "[[-1920.         -1080.          -486.86080535]\n",
      " [-1920.          1080.          -486.86080535]\n",
      " [ 1920.         -1080.          -486.86080535]\n",
      " [ 1920.          1080.          -486.86080535]\n",
      " [    0.             0.          -486.86080535]]\n",
      "[[-1920. -1080.]\n",
      " [-1920.  1080.]\n",
      " [ 1920. -1080.]\n",
      " [ 1920.  1080.]\n",
      " [    0.     0.]]\n",
      "[[-1920.         -1080.          -486.86080535]\n",
      " [-1920.          1080.          -486.86080535]\n",
      " [ 1920.         -1080.          -486.86080535]\n",
      " [ 1920.          1080.          -486.86080535]\n",
      " [    0.             0.          -486.86080535]]\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Camera:\n",
    "    position: np.ndarray#=field(default_factory=np.array([0., 0., 0.]))\n",
    "    # angle: np.ndarray#=field(default_factory=np.array([0., 1., 0.]))  # angle in degrees\n",
    "    angle: np.ndarray#=field(default_factory=np.array([0., 1., 0.]))  # angle in quaternion\n",
    "\n",
    "    focal_length: float=20.\n",
    "    resolution: np.ndarray=np.array([3840, 2160])\n",
    "    sensor_size: np.ndarray=np.array([36, 36])\n",
    "    fov: float=83.97443\n",
    "\n",
    "    def __post_init__(self):\n",
    "        beta, alpha, gamma = self.angle  # R_x, R_y, R_z | pitch, yaw, roll\n",
    "\n",
    "        sin_beta, cos_beta = np.sin(np.deg2rad(beta)), np.cos(np.deg2rad(beta))\n",
    "        sin_alpha, cos_alpha = np.sin(np.deg2rad(alpha)), np.cos(np.deg2rad(alpha))\n",
    "        sin_gamma, cos_gamma = np.sin(np.deg2rad(gamma)), np.cos(np.deg2rad(gamma))\n",
    "        self.rotation = np.array([\n",
    "            [cos_alpha*cos_beta, cos_alpha*sin_beta*sin_gamma - sin_alpha*cos_gamma, cos_alpha*sin_beta*cos_gamma + sin_alpha*sin_gamma],\n",
    "            [sin_alpha*cos_beta, sin_alpha*sin_beta*sin_gamma + cos_alpha*cos_gamma, sin_alpha*sin_beta*cos_gamma - cos_alpha*sin_gamma],\n",
    "            [-sin_beta, cos_beta*sin_gamma, cos_beta*cos_gamma]\n",
    "        ])\n",
    "\n",
    "        # r = R.from_quat(self.angle)\n",
    "        # self.rotation = r.as_matrix\n",
    "        # print(r.as_euler('', degrees=True))\n",
    "        # print('-'*30)\n",
    "\n",
    "        self.intrinsic = np.array([\n",
    "            [self.focal_length*self.resolution[0]/self.sensor_size[0], 0, self.resolution[0]/2],\n",
    "            [0, self.focal_length*self.resolution[1]/self.sensor_size[1], self.resolution[1]/2],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "\n",
    "    def pixel2ray(self, pixel):\n",
    "        pixel = np.append(pixel, np.zeros((pixel.shape[0], 1)) + 1, axis=-1)\n",
    "        # pixel = pixel / self.focal_length\n",
    "        translation = np.array(self.position) \n",
    "        camera_coor = pixel @ np.linalg.inv(self.intrinsic.T)\n",
    "        # print(camera_coor, self.angle, self.position)\n",
    "        # camera_coor = pixel @ np.linalg.inv(self.intrinsic).T\n",
    "        world_coor = (camera_coor @ self.rotation) + translation\n",
    "        # print(world_coor)\n",
    "\n",
    "        vector = world_coor - self.position\n",
    "        directional_vector = vector / np.linalg.norm(vector)\n",
    "        \n",
    "        return [Line(origin=coor, direction=vec) for coor, vec in zip(world_coor, directional_vector)]\n",
    "\n",
    "    def pixel2ray(self, pixel):\n",
    "        pixel = pixel - self.resolution/2\n",
    "        print(pixel)\n",
    "        pixel = np.append(pixel, -(self.resolution[1]/2)/(np.tan(self.fov/2))*np.ones((pixel.shape[0], 1)) + 1, axis=-1)\n",
    "        print(pixel)\n",
    "\n",
    "        # w_p = \n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Line:\n",
    "    origin: np.ndarray\n",
    "    direction: np.ndarray\n",
    "\n",
    "    @classmethod\n",
    "    def from_bbox_and_camera(cls, pixel, camera):\n",
    "        \n",
    "        return cls()\n",
    "\n",
    "\n",
    "def find_points(line_a: Line, line_b: Line):\n",
    "    n = np.cross(line_a.direction, line_b.direction)\n",
    "    d = np.abs(np.dot(n, line_a.origin - line_b.origin)) / np.linalg.norm(n)\n",
    "    \n",
    "    t_a = np.dot(np.cross(line_b.direction, n), (line_b.origin - line_a.origin)) / np.dot(n, n)\n",
    "    t_b = np.dot(np.cross(line_a.direction, n), (line_b.origin - line_a.origin)) / np.dot(n, n)\n",
    "\n",
    "    p_a = line_a.origin + t_a * line_a.direction\n",
    "    p_b = line_b.origin + t_b * line_b.direction\n",
    "\n",
    "    return (p_a + p_b) / 2\n",
    "\n",
    "colors = ['red', 'blue']\n",
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.set_xlabel(\"X\")\n",
    "# ax.set_ylabel(\"Y\")\n",
    "# ax.set_zlabel(\"Z\")\n",
    "\n",
    "cameras_ = [Camera(position=camera['position'], angle=camera['rotation']) for camera in output['cameras']]\n",
    "# for i, camera in enumerate(cameras_):\n",
    "#     ax.scatter(*camera.position, color=colors[i])\n",
    "\n",
    "lines = []\n",
    "for i, (bbox, camera) in enumerate(zip(output.get('bboxes'), cameras_)):\n",
    "    pixels = np.array([\n",
    "        [0, 0],\n",
    "        [0, 2160],\n",
    "        [3840, 0],\n",
    "        [3840, 2160],\n",
    "        [1920, 1080],\n",
    "    ])\n",
    "    rays = camera.pixel2ray(pixels)\n",
    "    stack_origin = np.stack([camera.position]*pixels.shape[0])\n",
    "    # ax.quiver(\n",
    "    #     stack_origin[:, 0],\n",
    "    #     stack_origin[:, 1],\n",
    "    #     stack_origin[:, 2],\n",
    "    #     np.array([r.direction for r in rays])[:, 0],\n",
    "    #     np.array([r.direction for r in rays])[:, 1],\n",
    "    #     np.array([r.direction for r in rays])[:, 2],\n",
    "    #     color=colors[i], length=1.0, arrow_length_ratio=.1, normalize=True\n",
    "    # )\n",
    "    # lines.append(rays[-1])\n",
    "\n",
    "# point = find_points(*lines)\n",
    "# print(point)\n",
    "# print(output['3D_location'])\n",
    "# ax.scatter(*point, color='purple')\n",
    "# ax.scatter(*output['3D_location'], color='orange')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = R.from_quat([-0.0695865452, 0.857597351, -0.120527431, -0.495134056])\n",
    "print(r.as_euler('xyz', degrees=True))\n",
    "print(r.as_euler('xzy', degrees=True))\n",
    "print(r.as_euler('yzx', degrees=True))\n",
    "print(r.as_euler('yxz', degrees=True))\n",
    "print(r.as_euler('zxy', degrees=True))\n",
    "print(r.as_euler('zyx', degrees=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "[[ 1.   0.  -3. ]\n",
      " [ 0.   0.5 -2. ]\n",
      " [ 0.   0.   1. ]]\n"
     ]
    }
   ],
   "source": [
    "m = np.array([\n",
    "    [1, 0, 3],\n",
    "    [0, 2, 4],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "m_inv = np.array([\n",
    "    [1, 0, -3],\n",
    "    [0, 1/2, -2],\n",
    "    [0, 0, 1],\n",
    "])\n",
    "print(m@m_inv)\n",
    "print(np.linalg.inv(m))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3a94878f375e66513a9f58a51086fe49a2b3775db248e5bb5453de8c77189b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
