{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from typing import List, Tuple\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3D': array([-2.00287218,  1.11557254, -2.92380786]), '2D': {'center': array([1884.,  734.]), 'size': array([ 47., 176.])}}\n",
      "{'3D': array([-2.00286907,  1.11557279, -2.92380769]), '2D': {'center': array([2306. ,  811.5]), 'size': array([106. , 262.5])}}\n"
     ]
    }
   ],
   "source": [
    "def extract_(l, s):\n",
    "    for elem in l:\n",
    "        if elem['id'] == s or elem['id'] == f'{s}_0':\n",
    "            return elem['values'][0]\n",
    "            \n",
    "with open('./solo_1/sequence.0/step0.frame_data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# captures = data['captures']\n",
    "# obj_1, obj_2 = captures[0], captures[1]\n",
    "# img_1, img_2 = obj_1['filename'], obj_2['filename']\n",
    "# obj_1_3d, bbox_1 = extract_(obj_1['annotations'], 'bounding box 3D'), extract_(obj_1['annotations'], 'bounding box')\n",
    "# obj_2_3d, bbox_2 = extract_(obj_2['annotations'], 'bounding box 3D'), extract_(obj_2['annotations'], 'bounding box')\n",
    "\n",
    "\n",
    "def extract(captures):\n",
    "    '''\n",
    "        Extract labels\n",
    "    '''\n",
    "\n",
    "    def _get_bbox(view):\n",
    "        '''\n",
    "            For each view, extract the 2D bounding box and\n",
    "        '''\n",
    "        bbox_3d, bbox_2d = extract_(view['annotations'], 'bounding box 3D'), extract_(view['annotations'], 'bounding box')\n",
    "        \n",
    "        # refine 3D location of the object\n",
    "        euler = R.from_quat(bbox_3d.get('rotation')).as_matrix()\n",
    "        obj_location = view.get('position') + np.dot(bbox_3d['translation'], euler)  # - bbox_3d['size']*np.array([-0.00389254, 0.49512566, 0.13212298])\n",
    "\n",
    "        # pre-process 2D bbox\n",
    "        bbox = {\n",
    "            'center': np.array(bbox_2d['origin']) + np.array(bbox_2d['dimension'])/2,\n",
    "            'size': np.array(bbox_2d['dimension'])/2,\n",
    "        }\n",
    "\n",
    "        return obj_location, bbox\n",
    "\n",
    "    bboxes, cameras = [], []\n",
    "\n",
    "    for capture in captures:  # per view\n",
    "        bbox_3d, bbox_2d = _get_bbox(capture)\n",
    "        bboxes.append({\n",
    "            '3D': bbox_3d,\n",
    "            '2D': bbox_2d\n",
    "        })\n",
    "        cameras.append({\n",
    "            'filename': capture['filename'],\n",
    "            'position': capture['position'],\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        # '3D_location': bboxes['3D'],\n",
    "        'bboxes': bboxes,\n",
    "        'cameras': cameras,\n",
    "    }\n",
    "\n",
    "output = extract(data['captures'])\n",
    "bboxes, cameras = output['bboxes'], output['cameras']\n",
    "\n",
    "print(bboxes[0])\n",
    "# print(cameras[0])\n",
    "print(bboxes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Camera:\n",
    "    focal_length: float\n",
    "    resolution: Tuple[int, int]\n",
    "    sensor_size: Tuple[int, int]\n",
    "\n",
    "    position: np.ndarray#=field(default_factory=np.array([0., 0., 0.]))\n",
    "    angle: np.ndarray#=field(default_factory=np.array([0., 1., 0.]))  # angle in degrees\n",
    "\n",
    "    def __post_init__(self):\n",
    "        beta, alpha, gamma = self.angle  # R_x, R_y, R_z | pitch, yaw, roll\n",
    "\n",
    "        sin_beta, cos_beta = np.sin(np.deg2rad(beta)), np.cos(np.deg2rad(beta))\n",
    "        sin_alpha, cos_alpha = np.sin(np.deg2rad(alpha)), np.cos(np.deg2rad(alpha))\n",
    "        sin_gamma, cos_gamma = np.sin(np.deg2rad(gamma)), np.cos(np.deg2rad(gamma))\n",
    "\n",
    "        self.rotation = np.array([\n",
    "            [cos_alpha*cos_beta, cos_alpha*sin_beta*sin_gamma - sin_alpha*cos_gamma, cos_alpha*sin_beta*cos_gamma + sin_alpha*sin_gamma],\n",
    "            [sin_alpha*cos_beta, sin_alpha*sin_beta*sin_gamma + cos_alpha*cos_gamma, sin_alpha*sin_beta*cos_gamma - cos_alpha*sin_gamma],\n",
    "            [-sin_beta, cos_beta*sin_gamma, cos_beta*cos_gamma]\n",
    "        ])\n",
    "        unit_vec = np.array([0, 0, 1])\n",
    "        # v = np.matmul(self.rotation, unit_vec.T)\n",
    "        v = unit_vec @ self.rotation\n",
    "        self.unit_angle = v / np.linalg.norm(v)\n",
    "\n",
    "        self.intrinsic = np.array([\n",
    "            [self.focal_length*self.resolution[0]/self.sensor_size[0], 0, self.resolution[0]/2],\n",
    "            [0, self.focal_length*self.resolution[1]/self.sensor_size[1], self.resolution[1]/2],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "\n",
    "    def pixel2ray(self, pixel):\n",
    "        pixel = np.append(pixel, np.zeros((pixel.shape[0], 1)) + 1, axis=-1)\n",
    "        # pixel = pixel / self.focal_length\n",
    "        translation = np.array(self.position) \n",
    "        camera_coor = pixel @ np.linalg.inv(self.intrinsic.T)\n",
    "        # camera_coor = pixel @ np.linalg.inv(self.intrinsic).T\n",
    "        world_coor = (camera_coor @ self.rotation) + translation\n",
    "\n",
    "        vector = world_coor - self.position\n",
    "        directional_vector = vector / np.linalg.norm(vector)\n",
    "\n",
    "        # return directional_vector\n",
    "        return Line(origin=world_coor, direction=directional_vector)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Line:\n",
    "    origin: np.ndarray\n",
    "    direction: np.ndarray\n",
    "\n",
    "\n",
    "def find_points(line_a: Line, line_b: Line):\n",
    "    n = np.cross(line_a.direction, line_b.direction)\n",
    "    d = np.abs(np.dot(n, line_a.origin - line_b.origin)) / np.linalg.norm(n)\n",
    "    \n",
    "    t_a = np.dot(np.cross(line_b.direction, n), (line_b.origin - line_a.origin)) / np.dot(n, n)\n",
    "    t_b = np.dot(np.cross(line_a.direction, n), (line_b.origin - line_a.origin)) / np.dot(n, n)\n",
    "\n",
    "    p_a = line_a.origin + t_a * line_a.direction\n",
    "    p_b = line_b.origin + t_b * line_b.direction\n",
    "\n",
    "    return (p_a + p_b) / 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'3D': array([-2.00287218,  1.11557254, -2.92380786]), '2D': {'center': array([1884.,  734.]), 'size': array([ 47., 176.])}}, {'3D': array([-2.00286907,  1.11557279, -2.92380769]), '2D': {'center': array([2306. ,  811.5]), 'size': array([106. , 262.5])}}] [{'filename': 'step0.camera_0.png', 'position': [8.0, 2.5, 3.0]}, {'filename': 'step0.camera.png', 'position': [-7.0, 2.5, 3.0]}]\n"
     ]
    }
   ],
   "source": [
    "def get_location(bboxes_list, cameras_list):\n",
    "    for bboxes, cameras in zip(bboxes_list, cameras_list):\n",
    "        print(bboxes, cameras)\n",
    "\n",
    "get_location([bboxes], [cameras])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3a94878f375e66513a9f58a51086fe49a2b3775db248e5bb5453de8c77189b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
